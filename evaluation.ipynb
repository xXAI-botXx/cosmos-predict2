{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97313dc",
   "metadata": {},
   "source": [
    "# Cosmos Predict 2 (Video2World) Physgen benchmark Evaluation\n",
    "\n",
    "-> you already downloaded and transformed the physgen dataset (as described in the README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af714ff3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"/workspace/checkpoints/...\"  # path to pt file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e46a0",
   "metadata": {},
   "source": [
    "### Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23c099",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# !conda create -n eval python=3.8 -y\n",
    "# !conda init\n",
    "# !conda activate eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1e19c",
   "metadata": {},
   "source": [
    "Activate now eval env and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e254a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install ipython\n",
    "# !pip install ipykernel\n",
    "# !pip install opencv-python\n",
    "# !pip install shapely\n",
    "# !pip install pytorch-msssim\n",
    "# !pip install scikit-image\n",
    "# !pip install -r requirements.txt\n",
    "# !pip install kornia\n",
    "# !pip install img-phy-sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5bae2",
   "metadata": {},
   "source": [
    "> Set 'eval' as your python env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32c538",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1347e00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f828e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27c389",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce970be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img, title=None, image_width=10, axis=False,\n",
    "           color_space=\"RGB\", cmap=None, cols=1, save_to=None,\n",
    "           hspace=0.2, wspace=0.2,\n",
    "           use_original_sytle=False, invert=False):\n",
    "    \"\"\"\n",
    "    Visualizes one or multiple images.\n",
    "\n",
    "    Image will be reshaped: [batch_size/images, width, height, channels]\n",
    "\n",
    "    ---\n",
    "    Parameters:\n",
    "    - img : np.ndarray\n",
    "        Images/Images with [width, height, channels] or for multiple: [batch_size/images, width, height, channels].\n",
    "    - title : str, optional (default=None)\n",
    "        Title of the whole plot.\n",
    "    - image_width : int, optional (default=5)\n",
    "        Width of one image in the plot.\n",
    "    - axis : bool, optional (default=False)\n",
    "        Whether to print the axis of the images or not.\n",
    "    - color_space : str, optional (default=\"RGB\")\n",
    "        The colorspace of the image: RGB, BGR, gray, HSV.\n",
    "    - cmap : str, optional (default=None)\n",
    "        Which cmap to use. Check all cmaps here out: https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "    - cols : int, optional (default=1)\n",
    "        Amount of columns in the plot.\n",
    "    - save_to : str, optional (default=None)\n",
    "        Path where to save the result image.\n",
    "    - hspace : float, optional (default=0.01)\n",
    "        Horizontal space between the images.\n",
    "    - wspace : float, optional (default=0.01)\n",
    "        Vertical space between the images.\n",
    "    - use_original_sytle : bool, optonial (default=False)\n",
    "        Whether the plot should use the current active matplotlib style or choosing a own one. \n",
    "    - invert : bool, optional (default=False)\n",
    "        Whether to invert the images or not.\n",
    "    \"\"\"\n",
    "    original_style = plt.rcParams.copy()\n",
    "\n",
    "    img_shape = img.shape\n",
    "    print(f\"Got images with shape: {img_shape}\")\n",
    "\n",
    "    # tranform the image to the right form\n",
    "    if len(img_shape) == 2:\n",
    "        img = np.reshape(img, shape=(1, img.shape[0], img.shape[1], 1))\n",
    "    elif len(img_shape) == 3:\n",
    "        # check if multiple gray images or multiple images with channel\n",
    "        # if img.shape[2] < img.shape[0] and img.shape[1] == img.shape[2]:\n",
    "        img = np.reshape(img, shape=(1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "        # else:\n",
    "        #     # there could be cases where this is wrong\n",
    "        #     img = np.reshape(img, shape=(img.shape[0], img.shape[1], img.shape[2], 1))\n",
    "    elif len(img_shape) != 4:\n",
    "        raise ValueError(f\"Image(s) have wrong shape! Founded shape: {img.shape}.\")\n",
    "\n",
    "    print(f\"Transformed shape to: {img_shape}\")\n",
    "\n",
    "    # invert images\n",
    "    if invert:\n",
    "        print(\"Invert images...\")\n",
    "        max_value = 2**(img.dtype.itemsize * 8) -1\n",
    "        scaling_func = lambda x: max_value - x\n",
    "        img = np.apply_along_axis(scaling_func, axis=0, arr=img)\n",
    "\n",
    "    # Set visualization settings\n",
    "    # aspect_ratio_width = img.shape[1] / img.shape[2]\n",
    "    aspect_ratio = img.shape[2] / img.shape[1]\n",
    "\n",
    "    n_images = img.shape[0]\n",
    "    rows = n_images//cols + int(n_images % cols > 0)\n",
    "\n",
    "    width = int(image_width * cols)\n",
    "    height = int(image_width * rows * aspect_ratio)\n",
    "\n",
    "    # set plt style\n",
    "    if not use_original_sytle:\n",
    "        plt_style = 'seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else np.random.choice(plt.style.available)\n",
    "        plt.style.use(plt_style)\n",
    "        print(f\"Using '{plt_style}' plotting style.\")\n",
    "\n",
    "    # plotting\n",
    "    print(f\"Making you a beautiful plot...\")\n",
    "    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(width, height))\n",
    "    try:\n",
    "        ax = ax.ravel()\n",
    "    except AttributeError:\n",
    "        ax = [ax]\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "    if type(title) == str:\n",
    "        fig.suptitle(title, fontsize=128, y=0.95)\n",
    "\n",
    "    for idx in range(len(ax)):\n",
    "        cur_ax = ax[idx]\n",
    "\n",
    "        if idx >= len(img):\n",
    "            cur_ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        cur_img = img[idx]\n",
    "\n",
    "        if color_space.lower() == \"bgr\":\n",
    "            cur_img = cv2.cvtColor(cur_img, cv2.COLOR_BGR2RGB)\n",
    "            used_cmap = None\n",
    "        elif color_space.lower() == \"rgb\":\n",
    "            cur_img = cur_img\n",
    "            used_cmap = None\n",
    "        elif color_space.lower() == \"hsv\":\n",
    "            cur_img = cv2.cvtColor(cur_img, cv2.COLOR_HSV2RGB)\n",
    "            used_cmap = None\n",
    "        elif color_space.lower() in [\"gray\", \"grey\", \"g\"]:\n",
    "            if len(cur_img.shape) == 3 and cur_img.shape[2]:\n",
    "                cur_img = cv2.cvtColor(cur_img, cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                cur_img = cur_img\n",
    "            print(cur_img.shape)\n",
    "            used_cmap = \"gray\"\n",
    "\n",
    "        if cmap:\n",
    "            used_cmap = cmap\n",
    "\n",
    "        if type(title) in [list, tuple]:\n",
    "            cur_ax.set_title(title[idx], fontsize=64)\n",
    "        if axis == False:\n",
    "            cur_ax.axis(\"off\")\n",
    "\n",
    "        cur_ax.imshow(cur_img, cmap=used_cmap)\n",
    "\n",
    "    if save_to:\n",
    "        os.makedirs(os.path.split(save_to)[0], exist_ok=True)\n",
    "        fig.savefig(save_to, dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if not use_original_sytle:\n",
    "        # reset to original plt style\n",
    "        plt.rcParams.update(original_style)\n",
    "\n",
    "def show_images(image_paths:list, title=None, image_width=5, axis=False,\n",
    "                color_space=\"gray\", cmap=None, \n",
    "                cols=2, save_to=None,\n",
    "                hspace=0.01, wspace=0.01,\n",
    "                use_original_sytle=False, invert=False):\n",
    "    \"\"\"\n",
    "    Visulalizes/shows one or multiple images.\n",
    "\n",
    "    ---\n",
    "    Parameters:\n",
    "    - image_paths : List[str]\n",
    "        List of paths to the images which should get visualized.\n",
    "    - title : str, optional (default=None)\n",
    "        Title of the whole plot.\n",
    "    - image_width : int, optional (default=5)\n",
    "        Width of one image in the plot.\n",
    "    - axis : bool, optional (default=False)\n",
    "        Whether to print the axis of the images or not.\n",
    "    - color_space : str, optional (default=\"RGB\")\n",
    "        The colorspace of the image: RGB, BGR, gray, HSV.\n",
    "    - cmap : str, optional (default=None)\n",
    "        Which cmap to use. Check all cmaps here out: https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "    - cols : int, optional (default=1)\n",
    "        Amount of columns in the plot.\n",
    "    - save_to : str, optional (default=None)\n",
    "        Path where to save the result image.\n",
    "    - hspace : float, optional (default=0.01)\n",
    "        Horizontal space between the images.\n",
    "    - wspace : float, optional (default=0.01)\n",
    "        Vertical space between the images.\n",
    "    - use_original_sytle : bool, optonial (default=False)\n",
    "        Whether the plot should use the current active matplotlib style or choosing a own one. \n",
    "    - invert : bool, optional (default=False)\n",
    "        Whether to invert the images or not.\n",
    "    \"\"\"\n",
    "    if color_space.lower() == \"rgb\":\n",
    "        images = np.array([cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB) for img in image_paths])\n",
    "    elif color_space.lower() == \"hsv\":\n",
    "        images = np.array([cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2HSV) for img in image_paths])\n",
    "    else:\n",
    "        images = np.array([cv2.imread(img) for img in image_paths])\n",
    "    imshow(images, title=title, image_width=image_width, axis=axis,\n",
    "           color_space=color_space, cmap=cmap, cols=cols, save_to=save_to,\n",
    "           hspace=hspace, wspace=wspace,\n",
    "           use_original_sytle=use_original_sytle, invert=invert)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ed2ba",
   "metadata": {},
   "source": [
    "### Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67713680",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f\"./eval/{model_1}\"):\n",
    "    shutil.rmtree(f\"./eval/{model_1}\")\n",
    "    print(f\"Cleaned eval ('./eval/{model_1}')\")\n",
    "\n",
    "if os.path.exists(f\"../../data/eval/{model_1}\"):\n",
    "    shutil.rmtree(f\"../../data/eval/{model_1}\")\n",
    "    print(f\"Cleaned eval ('../../data/eval/{model_1}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa0204",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "FIXME\n",
    "\n",
    "command = (\n",
    "  f\"python test.py \"\n",
    "  f\"--dataroot {data_1} \"\n",
    "  f\"--name {model_1} \"\n",
    "  f\"--model {model_1_type} \"\n",
    "  f\"--batch_size {batch_size} \"\n",
    "  f\"--dataset_mode {data_1_type} \"\n",
    "  f\"--input_nc {input_channels} \"\n",
    "  f\"--output_nc 1 \"\n",
    "  f\"--load_size {image_size} \"\n",
    "  f\"--netG unet_256 \"\n",
    "  f\"--max_dataset_size {data_to_process_size} \"\n",
    "  f\"--num_test {data_to_process_size} \"\n",
    "  f\"--results_dir ./eval/{model_1} \"\n",
    "  f\"--phase test \"\n",
    "  f\"--eval\"\n",
    ")\n",
    "# ./eval/{model_1} \"\n",
    "# ~/data/eval/{model_1} \"\n",
    "\n",
    "if model_variation == \"hexa_wave_net\":\n",
    "  command += f\" --model_type {model_variation}\"\n",
    "\n",
    "if different_naming_1:\n",
    "  command += \" --different_building_naming\"\n",
    "\n",
    "if data_1_type == \"physgen\":\n",
    "  command += f\" --variation {physgen_variation}\"\n",
    "  if reflexion_channels:\n",
    "    command += f\" --reflexion_channels\"\n",
    "    command += f\" --reflexion_steps {reflexion_steps}\"\n",
    "    if reflexions_as_channels:\n",
    "      command += f\" --reflexions_as_channels\"\n",
    "\n",
    "# Finally run it\n",
    "!{command}\n",
    "\n",
    "FIXME -> put command from README inference part here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f455c15",
   "metadata": {},
   "source": [
    "FIXME\n",
    "\n",
    "maybe have to add also the real input and target now\n",
    "\n",
    "additionally:\n",
    "\n",
    "extract picture prediction from video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf9ed0",
   "metadata": {},
   "source": [
    "### Extract Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f09bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "evaluation_path = f\"./eval/{model_1}/{model_1}/test_latest/images\"\n",
    "target_path = f\"../../data/eval/{model_1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05b8bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python eval_extractor.py \\\n",
    "    --name {model_1} \\\n",
    "    --evaluation_path {evaluation_path} \\\n",
    "    --target_path {target_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869682b",
   "metadata": {},
   "source": [
    "### Calc Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1402d48",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python eval_metrics.py \\\n",
    "    --data_dir ../../data/eval/{model_1}/real \\\n",
    "    --pred_dir ../../data/eval/{model_1}/pred \\\n",
    "    --osm_dir ../../data/eval/{model_1}/osm \\\n",
    "    --output ./eval_results/evaluation_{model_1}.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a322e373",
   "metadata": {},
   "source": [
    "### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ede05",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mae_model_1_name = f'MAE_{model_1}'\n",
    "los_mae_model_1_name = f'LoS_MAE_{model_1}'\n",
    "nlos_mae_model_1_name = f'NLoS_MAE_{model_1}'\n",
    "mape_model_1_name = f'MAPE_{model_1}'\n",
    "los_wmape_model_1_name = f'LoS_wMAPE_{model_1}'\n",
    "nlos_wmape_model_1_name = f'NLoS_wMAPE_{model_1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8b861",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(f\"./eval_results/evaluation_{model_1}.csv\")\n",
    "# df_1 = df_1.drop(columns=[\"LoS_MAE\", \"NLoS_MAE\", \"LoS_wMAPE\", \"NLoS_wMAPE\"])\n",
    "df_1 = df_1.rename(columns={'MAE': mae_model_1_name, \n",
    "                            'LoS_MAE': los_mae_model_1_name,\n",
    "                            'NLoS_MAE': nlos_mae_model_1_name,\n",
    "                            'MAPE':mape_model_1_name,\n",
    "                            'LoS_wMAPE': los_wmape_model_1_name,\n",
    "                            'NLoS_wMAPE': nlos_wmape_model_1_name\n",
    "                            }\n",
    "                   )\n",
    "# extract sample_ids\n",
    "sample_id_series = df_1[\"sample_id\"].str.extract(r'^(\\d+)_')[0]\n",
    "if sample_id_series.isna().sum() > 1:\n",
    "    sample_id_series = df_1[\"sample_id\"].str.extract(r'(\\d+)')[0]\n",
    "if sample_id_series.isna().sum() > 1:\n",
    "    raise ValueError(f\"Found {sample_id_series.isna().sum()} Nans\")\n",
    "df_1[\"sample_id\"] = sample_id_series\n",
    "print(\"Nan found in sample ids:\", df_1[\"sample_id\"].isna().sum())\n",
    "df_1 = df_1.dropna(subset=[\"sample_id\"])\n",
    "df_1[\"sample_id\"] = df_1[\"sample_id\"].astype(int)\n",
    "merged_df = df_1\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6434d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt_style = 'seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else np.random.choice(plt.style.available)\n",
    "plt.style.use(plt_style)\n",
    "print(f\"Using '{plt_style}' plotting style.\")\n",
    "\n",
    "values_0 = [\n",
    "    merged_df[mae_model_1_name],\n",
    "    merged_df[los_mae_model_1_name],\n",
    "    merged_df[nlos_mae_model_1_name],\n",
    "]\n",
    "\n",
    "labels_0 = [\n",
    "    \"MAE\",\n",
    "    \"NLoS MAE\",\n",
    "    \"LoS MAE\"\n",
    "]\n",
    "\n",
    "values_1 = [\n",
    "    merged_df[mape_model_1_name],\n",
    "    merged_df[los_wmape_model_1_name],\n",
    "    merged_df[nlos_wmape_model_1_name]\n",
    "]\n",
    "\n",
    "labels_1 = [\n",
    "    \"MAPE\",\n",
    "    \"LoS wMAPE\",\n",
    "    \"NLoS wMAPE\"\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(12, 12))\n",
    "ax[0].boxplot(values_0, notch=False)\n",
    "ax[0].set_xticks(range(1, len(labels_0) + 1))\n",
    "ax[0].set_xticklabels(labels_0, rotation=15)\n",
    "ax[0].set_title(\"Error Metrics Distribution\")\n",
    "\n",
    "ax[1].boxplot(values_1, notch=False)\n",
    "ax[1].set_xticks(range(1, len(labels_1) + 1))\n",
    "ax[1].set_xticklabels(labels_1, rotation=15)\n",
    "ax[1].set_title(\"Error Metrics Distribution\")\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nMAE\\n    - {model_1}: {merged_df[mae_model_1_name].mean():>0.2f}\")\n",
    "# print(f\"\\nMAPE\\n    - {model_1}: {merged_df[mape_model_1_name].mean():>0.2f}\")\n",
    "\n",
    "print(f\"\\nLoS MAE\\n    - {model_1}: {merged_df[los_mae_model_1_name].mean():>0.2f}\")\n",
    "print(f\"\\nNLoS MAE\\n    - {model_1}: {merged_df[nlos_mae_model_1_name].mean():>0.2f}\")\n",
    "print(f\"\\nLoS wMAPE\\n    - {model_1}: {merged_df[los_wmape_model_1_name].mean():>0.2f}\")\n",
    "print(f\"\\nNLoS wMAPE\\n    - {model_1}: {merged_df[nlos_wmape_model_1_name].mean():>0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d57580",
   "metadata": {},
   "source": [
    "Example Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371562fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def get_unique_hsv_cmap():\n",
    "    unique_hsv_map = plt.get_cmap(\"hsv\")(np.linspace(0, 1, 256))    # np.arange(0, 256)\n",
    "    hsv_map = plt.get_cmap(\"hsv\")\n",
    "    for cur_idx in range(256):\n",
    "        r, g, b, a = hsv_map(cur_idx)\n",
    "        if r > 0.99 and g < (170/255):\n",
    "            gray_value = cur_idx*8 / 255.0\n",
    "            unique_hsv_map[cur_idx] = (gray_value, gray_value, gray_value, 1.0)\n",
    "        else:\n",
    "            break\n",
    "    unique_hsv = ListedColormap(unique_hsv_map)\n",
    "    plt.colormaps.register(name=\"unique_hsv\", cmap=unique_hsv, force=True)\n",
    "    return unique_hsv\n",
    "\n",
    "get_unique_hsv_cmap()\n",
    "plt.get_cmap(\"unique_hsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434684ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_same_pred_real_samples(pred_path:str, real_path:str, input_path:str, n_samples:int, ids=None):\n",
    "    if not ids:\n",
    "        # choose n random samples\n",
    "        samples = random.sample(os.listdir(pred_path), n_samples)\n",
    "        pred_samples = [os.path.join(pred_path, cur_image) for cur_image in samples]\n",
    "\n",
    "        # get the used id's\n",
    "        ids = []\n",
    "        for cur_image in samples:\n",
    "            cur_id = re.findall(r'\\d+', string=cur_image)\n",
    "            if len(cur_id) <= 0:\n",
    "                raise ValueError(f\"One image has no ID: {cur_image}\")\n",
    "            cur_id = cur_id[-1]\n",
    "            ids += [cur_id]\n",
    "    else:\n",
    "        # get pred image\n",
    "        pred_image_samples = []\n",
    "        for target_id in ids:\n",
    "            found = False\n",
    "            for cur_image in os.listdir(real_path):\n",
    "                cur_id = re.findall('\\d+', string=cur_image)\n",
    "                if len(cur_id) > 0:\n",
    "                    cur_id = cur_id[-1]\n",
    "                    if cur_id == target_id:\n",
    "                        pred_image_samples += [cur_image]\n",
    "                        found = True\n",
    "                        break\n",
    "\n",
    "            if not found:\n",
    "                raise ValueError(f\"Does not found pred image with id: {target_id}\")\n",
    "        pred_samples = [os.path.join(pred_path, cur_image) for cur_image in pred_image_samples]\n",
    "\n",
    "    # get real image\n",
    "    real_image_samples = []\n",
    "    for target_id in ids:\n",
    "        found = False\n",
    "        for cur_image in os.listdir(real_path):\n",
    "            cur_id = re.findall('\\d+', string=cur_image)\n",
    "            if len(cur_id) > 0:\n",
    "                cur_id = cur_id[-1]\n",
    "                if cur_id == target_id:\n",
    "                    real_image_samples += [cur_image]\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "        if not found:\n",
    "            raise ValueError(f\"Does not found real image with id: {target_id}\")\n",
    "\n",
    "    target_samples = [os.path.join(real_path, cur_image) for cur_image in real_image_samples]\n",
    "\n",
    "    # get real image\n",
    "    input_image_samples = []\n",
    "    if input_path:\n",
    "        for target_id in ids:\n",
    "            found = False\n",
    "            for cur_image in os.listdir(input_path):\n",
    "                cur_id = re.findall('\\d+', string=cur_image)\n",
    "                if len(cur_id) > 0:\n",
    "                    cur_id = cur_id[-1]\n",
    "                    if cur_id == target_id:\n",
    "                        input_image_samples += [cur_image]\n",
    "                        found = True\n",
    "                        break\n",
    "\n",
    "            if not found:\n",
    "                raise ValueError(f\"Does not found input image with id: {target_id}\")\n",
    "\n",
    "    input_samples = [os.path.join(input_path, cur_image) for cur_image in input_image_samples]\n",
    "\n",
    "    return input_samples, target_samples, pred_samples, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32634590",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot(ax, path, title=\"\", sub_image=None, cmap=\"turbo\", plot=True, normalize=True, vmin=0.0, vmax=1.0):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "    # print(\"\\n\", title, img.max())\n",
    "    # print(\"\\n\", title, img.min())\n",
    "    img = 255 - img\n",
    "    # print(img.max())\n",
    "\n",
    "    if sub_image:\n",
    "        img_2 = cv2.imread(sub_image, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "        img_2 = 255 - img_2\n",
    "\n",
    "        assert img_2.shape == img.shape, \"Shape mismatch\"\n",
    "        img = np.abs(img - img_2)\n",
    "        # img = img - img_2\n",
    "        # img[img < 0] = img[img < 0] * -1\n",
    "\n",
    "    # print(title, img.max())\n",
    "\n",
    "    # normalize\n",
    "    if normalize:\n",
    "        img = img / 255.0\n",
    "        if sub_image:\n",
    "            img_2 = img_2 / 255.0\n",
    "\n",
    "    # print(title, img.max())\n",
    "\n",
    "    if plot:\n",
    "        ax.axis(\"off\")\n",
    "        color_ax = ax.imshow(img, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(title)\n",
    "        plt.colorbar(color_ax, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911ab4e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 3\n",
    "\n",
    "input_samples, real, pred_model, ids = get_same_pred_real_samples(f\"../../data/eval/{model_1}/pred\",\n",
    "                                                                  f\"../../data/eval/{model_1}/real\",\n",
    "                                                                  f\"../../data/eval/{model_1}/osm\",\n",
    "                                                                  n_samples)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=n_samples, ncols=4, figsize=(4*4, n_samples*4))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "for idx, cur_path in enumerate(input_samples):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"Input\", cmap=\"gray\")\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"{model_1}\")  #, vmax=100)\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][2], path=cur_path, title=f\"ground truth\")  # , vmax=100)\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][3], path=cur_path, title=f\"Difference\", sub_image=real[idx])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6cbe57",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_samples, ncols=4, figsize=(4*4, n_samples*4))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "cur_cmap = \"nipy_spectral\"\n",
    "\n",
    "for idx, cur_path in enumerate(input_samples):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"Input\", cmap=\"gray\")\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"{model_1}\", cmap=cur_cmap)  #, vmax=100)\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][2], path=cur_path, title=f\"ground truth\", cmap=cur_cmap)  # , vmax=100)\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][3], path=cur_path, title=f\"Difference\", sub_image=real[idx], cmap=cur_cmap)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956d5d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "\n",
    "input_samples, real, pred_model, ids = get_same_pred_real_samples(f\"../../data/eval/{model_1}/pred\",\n",
    "                                                                  f\"../../data/eval/{model_1}/real\",\n",
    "                                                                  f\"../../data/eval/{model_1}/osm\",\n",
    "                                                                  n_samples)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=n_samples, ncols=4, figsize=(4*4, n_samples*6))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "for idx, cur_path in enumerate(input_samples):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"Input\", cmap=\"gray\")\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"{model_1}\", cmap=\"unique_hsv\")\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][2], path=cur_path, title=f\"ground truth\", cmap=\"unique_hsv\")\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][3], path=cur_path, title=f\"Difference\", sub_image=real[idx])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e1a67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_samples, ncols=2, figsize=(2*4, n_samples*6))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"{model_1}\")\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"ground truth\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da6e292",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(1*4, n_samples*6))\n",
    "\n",
    "plot(ax, path=pred_model[0], title=f\"{model_1}\", sub_image=real[0])\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025e611",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_samples, ncols=1, figsize=(1*4, n_samples*6))\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx], path=cur_path, title=f\"{model_1}\", sub_image=real[idx], cmap=\"plasma\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f135608",
   "metadata": {},
   "source": [
    "Inspect some single images in more detail here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349c9ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.measure import block_reduce\n",
    "\n",
    "def plot_image_with_values(img, block_size=8):\n",
    "    # Compute mean over non-overlapping blocks\n",
    "    mean_img = block_reduce(img, block_size=(block_size, block_size), func=np.mean)\n",
    "    max_value = mean_img.max()\n",
    "\n",
    "    # Plot the mean image\n",
    "    plt.imshow(mean_img, cmap='gray', interpolation='nearest')\n",
    "    plt.colorbar(label='Mean Value')\n",
    "\n",
    "    # Annotate each block with the mean\n",
    "    for i in range(mean_img.shape[0]):\n",
    "        for j in range(mean_img.shape[1]):\n",
    "            val = mean_img[i, j]\n",
    "            color = 'white' if val < max_value/1.5 else 'black'\n",
    "            # color = int(255 - val)\n",
    "            plt.text(j, i, f'{val:.1f}', ha='center', va='center',\n",
    "                     color=color, fontsize=6)\n",
    "\n",
    "    plt.title(f'Mean Values over {block_size}x{block_size} Blocks')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72b887",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img_path = pred_model[0]\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE).astype(float)\n",
    "\n",
    "plot_image_with_values(img, block_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c9d21f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img = plot(None, path=pred_model[0], title=f\"{model_1}\", sub_image=real[idx], plot=False)\n",
    "plot_image_with_values(img, block_size=16)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
